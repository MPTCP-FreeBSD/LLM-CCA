{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to convert true actions\n",
    "# def convert_to_classes(action):\n",
    "#     if action < 0.5:\n",
    "#         return 0\n",
    "#     elif action < 1.5:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 2\n",
    "# Function to convert normalized actions back to original CWND values\n",
    "def convert_to_original_cwnd(action_normalized):\n",
    "    # Constants for inverse normalization\n",
    "    max_cwnd_value = 1575424\n",
    "    min_cwnd_value = 4344\n",
    "\n",
    "    # Inverse normalization formula to convert normalized action back to original CWND value\n",
    "    cwnd_original = action_normalized * (max_cwnd_value - min_cwnd_value) + min_cwnd_value\n",
    "\n",
    "    return cwnd_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Directory containing the log files (update this path as needed)\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Directory containing the log files (update this path as needed)\n",
    "log_dir = r'D:\\LLM-CCA testing\\Prague'\n",
    "\n",
    "# Initialize lists to store the data\n",
    "epoch_numbers = []\n",
    "mean_losses = []\n",
    "median_losses = []\n",
    "mean_accuracies = []\n",
    "mean_cpu_usage = []\n",
    "mean_ram_usage = []\n",
    "mean_gpu_usage = []\n",
    "mean_vram_usage = []\n",
    "mean_disk_read_speed = []\n",
    "mean_disk_write_speed = []\n",
    "\n",
    "# Read all the custom_logs_epoch_train_*.json files\n",
    "log_files = [f for f in os.listdir(log_dir) if f.startswith('custom_logs_epoch_train_') and f.endswith('.json')]\n",
    "\n",
    "# Sort the log files based on the epoch number\n",
    "log_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "# Loop through each log file and extract relevant metrics\n",
    "for log_file in log_files:\n",
    "    epoch_number = int(log_file.split('_')[-1].split('.')[0])\n",
    "    epoch_numbers.append(epoch_number)\n",
    "\n",
    "    with open(os.path.join(log_dir, log_file), 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        losses = [step['train_loss'] for step in data['steps']]\n",
    "        actions_preds = [step['actions_pred'] for step in data['steps']]\n",
    "        actions = [step['actions'] for step in data['steps']]\n",
    "        \n",
    "        # Calculate mean and median losses\n",
    "        mean_loss = np.mean(losses)\n",
    "        median_loss = np.median(losses)\n",
    "        \n",
    "        mean_losses.append(mean_loss)\n",
    "        median_losses.append(median_loss)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracies = []\n",
    "        for preds, true_actions in zip(actions_preds, actions):\n",
    "            preds_array = np.array(preds)\n",
    "            true_actions_array = np.array(true_actions)\n",
    "            true_actions_classes = np.vectorize(convert_to_classes)(true_actions_array.flatten())\n",
    "            preds_indices = preds_array.argmax(axis=1).flatten()\n",
    "            accuracy = (preds_indices == true_actions_classes).mean()\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        mean_accuracy = np.mean(accuracies) if accuracies else None\n",
    "        mean_accuracies.append(mean_accuracy)\n",
    "\n",
    "        # Gather resource usage metrics\n",
    "        cpu_usages = [step['CPU Usage'] for step in data['steps']]\n",
    "        ram_usages = [step['RAM Usage'] for step in data['steps']]\n",
    "        gpu_usages = [step['GPU Usage'] for step in data['steps']]\n",
    "        vram_usages = [step['VRAM Usage'] for step in data['steps']]\n",
    "        disk_read_speeds = [step['Disk Read Speed (MB/s)'] for step in data['steps']]\n",
    "        disk_write_speeds = [step['Disk Write Speed (MB/s)'] for step in data['steps']]\n",
    "\n",
    "        # Calculate mean resource usages\n",
    "        mean_cpu_usage.append(np.mean(cpu_usages))\n",
    "        mean_ram_usage.append(np.mean(ram_usages))\n",
    "        mean_gpu_usage.append(np.mean(gpu_usages))\n",
    "        mean_vram_usage.append(np.mean(vram_usages))\n",
    "        mean_disk_read_speed.append(np.mean(disk_read_speeds))\n",
    "        mean_disk_write_speed.append(np.mean(disk_write_speeds))\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "df = pd.DataFrame({\n",
    "    'Epoch': epoch_numbers,\n",
    "    'Mean Loss': mean_losses,\n",
    "    'Median Loss': median_losses,\n",
    "    'Mean Accuracy': mean_accuracies,\n",
    "    'Mean CPU Usage': mean_cpu_usage,\n",
    "    'Mean RAM Usage': mean_ram_usage,\n",
    "    'Mean GPU Usage': mean_gpu_usage,\n",
    "    'Mean VRAM Usage': mean_vram_usage,\n",
    "    'Mean Disk Read Speed': mean_disk_read_speed,\n",
    "    'Mean Disk Write Speed': mean_disk_write_speed,\n",
    "})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Plot Mean Loss and Mean Accuracy\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.plot(df['Epoch'], df['Mean Loss'], marker='o', label='Mean Loss', color='blue')\n",
    "plt.plot(df['Epoch'], df['Median Loss'], marker='x', label='Median Loss', color='orange')\n",
    "plt.title('Mean and Median Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.plot(df['Epoch'], df['Mean Accuracy'], marker='o', label='Mean Accuracy', color='green')\n",
    "plt.title('Mean Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)  # Assuming accuracy is between 0 and 1\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot Mean Resource Usage\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.plot(df['Epoch'], df['Mean CPU Usage'], marker='o', label='Mean CPU Usage', color='blue')\n",
    "plt.title('Mean CPU Usage over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('CPU Usage (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.plot(df['Epoch'], df['Mean RAM Usage'], marker='o', label='Mean RAM Usage', color='orange')\n",
    "plt.title('Mean RAM Usage over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RAM Usage (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.plot(df['Epoch'], df['Mean GPU Usage'], marker='o', label='Mean GPU Usage', color='green')\n",
    "plt.title('Mean GPU Usage over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('GPU Usage (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.plot(df['Epoch'], df['Mean Disk Read Speed'], marker='o', label='Mean Disk Read Speed', color='purple')\n",
    "plt.plot(df['Epoch'], df['Mean Disk Write Speed'], marker='x', label='Mean Disk Write Speed', color='red')\n",
    "plt.title('Mean Disk Read and Write Speed over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Speed (MB/s)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Directory containing the log files (update this path as needed)\n",
    "log_dir = r'C:\\Users\\deols\\OneDrive\\Desktop\\Log Viz\\train_log_data'\n",
    "\n",
    "# Initialize lists to store the data\n",
    "epoch_numbers = []\n",
    "mean_losses = []\n",
    "median_losses = []\n",
    "mean_accuracies = []\n",
    "\n",
    "# Read all the custom_logs_epoch_train_*.json files\n",
    "log_files = [f for f in os.listdir(log_dir) if f.startswith('custom_logs_epoch_train_') and f.endswith('.json')]\n",
    "\n",
    "# Sort the log files based on the epoch number\n",
    "log_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "# Loop through each log file and extract mean and median losses, and accuracies\n",
    "for log_file in log_files:\n",
    "    epoch_number = int(log_file.split('_')[-1].split('.')[0])\n",
    "    epoch_numbers.append(epoch_number)\n",
    "\n",
    "    with open(os.path.join(log_dir, log_file), 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        losses = [step['train_loss'] for step in data['steps']]\n",
    "        actions_preds = [step['actions_pred'] for step in data['steps']]  # Ensure this key exists in your logs\n",
    "        actions = [step['actions'] for step in data['steps']]  # Ground truth actions\n",
    "        \n",
    "        # Calculate mean and median losses\n",
    "        mean_loss = sum(losses) / len(losses)\n",
    "        median_loss = pd.Series(losses).median()\n",
    "        \n",
    "        mean_losses.append(mean_loss)\n",
    "        median_losses.append(median_loss)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracies = []\n",
    "        for preds, true_actions in zip(actions_preds, actions):\n",
    "            preds_array = np.array(preds)  # Shape: (1, 3, 20)\n",
    "            true_actions_array = np.array(true_actions)  # Shape: (1, 20, 1)\n",
    "\n",
    "            # Convert true actions to classes\n",
    "            true_actions_classes = np.vectorize(convert_to_classes)(true_actions_array.flatten())  # Shape: (20,)\n",
    "\n",
    "            # Get the index of the maximum predicted value\n",
    "            preds_indices = preds_array.argmax(axis=1).flatten()  # Shape: (20,)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = (preds_indices == true_actions_classes).mean()\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "            # if accuracy != 0:\n",
    "            #     print(\"accuracy\", accuracy)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            # print(\"preds_indices\",preds_indices)\n",
    "            # print(\"true_actions_classes\",true_actions_classes)\n",
    "            # print(\"preds_indices.shape\",preds_indices.shape)\n",
    "            # print(\"preds_array.shape\",preds_array.shape)\n",
    "            # print(\"true_actions_classes.shape\",true_actions_classes.shape)\n",
    "\n",
    "        mean_accuracy = np.mean(accuracies) if accuracies else None\n",
    "        mean_accuracies.append(mean_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "df = pd.DataFrame({\n",
    "    'Epoch': epoch_numbers,\n",
    "    'Mean Loss': mean_losses,\n",
    "    'Median Loss': median_losses,\n",
    "    'Mean Accuracy': mean_accuracies\n",
    "})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Mean Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df['Epoch'], df['Mean Loss'], marker='o', label='Mean Loss', color='blue')\n",
    "plt.plot(df['Epoch'], df['Median Loss'], marker='x', label='Median Loss', color='orange')\n",
    "plt.title('Mean and Median Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot Mean Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df['Epoch'], df['Mean Accuracy'], marker='o', label='Mean Accuracy', color='green')\n",
    "plt.title('Mean Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim(0, 1)  # Assuming accuracy is between 0 and 1\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Plot mean average loss vs epoch number\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['Epoch'], df['Mean Loss'], label='Mean Loss', marker='o', color='blue')\n",
    "plt.plot(df['Epoch'], df['Median Loss'], label='Median Loss', marker='x', color='green')\n",
    "plt.title('Mean and Median Loss vs Epoch Number')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "# Plot loss vs step for each epoch\n",
    "\n",
    "for index in range(0, len(log_files), 10):\n",
    "    log_file = log_files[index]\n",
    "    # print(log_file)\n",
    "    epoch_number = int(log_file.split('_')[-1].split('.')[0])\n",
    "    \n",
    "    with open(os.path.join(log_dir, log_file), 'r') as file:\n",
    "        data = json.load(file)\n",
    "        steps = [step['step'] for step in data['steps']]\n",
    "        losses = [step['train_loss'] for step in data['steps']]    \n",
    "    plt.plot(steps, losses, label=f'Epoch {epoch_number}', marker='o')\n",
    "plt.title(f'Loss vs Step for Epoch {epoch_number}')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# # Plot loss vs step for each epoch\n",
    "# for log_file in log_files:\n",
    "#     epoch_number = int(log_file.split('_')[-1].split('.')[0])\n",
    "    \n",
    "#     with open(os.path.join(log_dir, log_file), 'r') as file:\n",
    "#         data = json.load(file)\n",
    "#         steps = [step['step'] for step in data['steps']]\n",
    "#         losses = [step['train_loss'] for step in data['steps']]\n",
    "    \n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.plot(steps, losses, label=f'Epoch {epoch_number}', marker='o')\n",
    "#     plt.title(f'Loss vs Step for Epoch {epoch_number}')\n",
    "#     plt.xlabel('Step')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directory containing the log files (update this path as needed)\n",
    "log_dir = r'C:\\Users\\deols\\OneDrive\\Desktop\\Log Viz\\train_log_data'\n",
    "\n",
    "# Select epochs to plot\n",
    "selected_epochs = [1, 10, 20, 30, 40]\n",
    "metrics = {\n",
    "    'steps': [],\n",
    "    'accuracies': {}\n",
    "}\n",
    "\n",
    "# Read all the custom_logs_epoch_train_*.json files\n",
    "log_files = [f for f in os.listdir(log_dir) if f.startswith('custom_logs_epoch_train_') and f.endswith('.json')]\n",
    "log_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "# Loop through each log file to extract accuracy data for selected epochs\n",
    "for log_file in log_files:\n",
    "    epoch_number = int(log_file.split('_')[-1].split('.')[0])\n",
    "    \n",
    "    if epoch_number in selected_epochs:\n",
    "        with open(os.path.join(log_dir, log_file), 'r') as file:\n",
    "            data = json.load(file)\n",
    "            steps = [step['step'] for step in data['steps']]\n",
    "            actions_preds = [step['actions_pred'] for step in data['steps']]\n",
    "            actions = [step['actions'] for step in data['steps']]\n",
    "            \n",
    "            # Store steps for plotting (assuming they are consistent across selected epochs)\n",
    "            if not metrics['steps']:\n",
    "                metrics['steps'] = steps\n",
    "            \n",
    "            # Calculate accuracy for each step\n",
    "            accuracies = []\n",
    "            for preds, true_actions in zip(actions_preds, actions):\n",
    "                preds_array = np.array(preds)\n",
    "                true_actions_array = np.array(true_actions).flatten()\n",
    "                \n",
    "                # Convert true actions to classes\n",
    "                true_actions_classes = np.vectorize(convert_to_classes)(true_actions_array)\n",
    "                preds_indices = preds_array.argmax(axis=1).flatten()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                accuracy = (preds_indices == true_actions_classes).mean()\n",
    "                accuracies.append(accuracy)\n",
    "            \n",
    "            # Store accuracies for the current epoch\n",
    "            metrics['accuracies'][epoch_number] = accuracies\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot Accuracy vs Step for each selected epoch\n",
    "for epoch in selected_epochs:\n",
    "    if epoch in metrics['accuracies']:\n",
    "        plt.plot(metrics['steps'], metrics['accuracies'][epoch], marker='o', label=f'Epoch {epoch}')\n",
    "\n",
    "plt.title('Accuracy vs Step for Selected Epochs')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)  # Assuming accuracy is between 0 and 1\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directory containing the log files (update this path as needed)\n",
    "log_dir = r'C:\\Users\\deols\\OneDrive\\Desktop\\Log Viz\\train_log_data'\n",
    "\n",
    "# Read all the custom_logs_epoch_train_*.json files\n",
    "log_files = [f for f in os.listdir(log_dir) if f.startswith('custom_logs_epoch_train_') and f.endswith('.json')]\n",
    "log_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "# Initialize lists for storing metrics\n",
    "selected_epochs = [1, 10, 20]  # Add more as needed\n",
    "metrics = {\n",
    "    'steps': [],\n",
    "    'cpu_usages': {},\n",
    "    'ram_usages': {},\n",
    "    'gpu_usages': {},\n",
    "    'vram_usages': {},\n",
    "    'disk_read_speeds': {},\n",
    "    'disk_write_speeds': {}\n",
    "}\n",
    "\n",
    "# Loop through the log files to extract metrics for selected epochs\n",
    "for log_file in log_files:\n",
    "    epoch_number = int(log_file.split('_')[-1].split('.')[0])\n",
    "    \n",
    "    if epoch_number in selected_epochs:\n",
    "        with open(os.path.join(log_dir, log_file), 'r') as file:\n",
    "            data = json.load(file)\n",
    "            steps = [step['step'] for step in data['steps']]\n",
    "            cpu_usages = [step['CPU Usage'] for step in data['steps']]\n",
    "            ram_usages = [step['RAM Usage'] for step in data['steps']]\n",
    "            gpu_usages = [step['GPU Usage'] for step in data['steps']]\n",
    "            vram_usages = [step['VRAM Usage'] for step in data['steps']]\n",
    "            disk_read_speeds = [step['Disk Read Speed (MB/s)'] for step in data['steps']]\n",
    "            disk_write_speeds = [step['Disk Write Speed (MB/s)'] for step in data['steps']]\n",
    "\n",
    "            # Store metrics by epoch number\n",
    "            metrics['steps'] = steps  # Assuming steps are the same for each selected epoch\n",
    "            metrics['cpu_usages'][epoch_number] = cpu_usages\n",
    "            metrics['ram_usages'][epoch_number] = ram_usages\n",
    "            metrics['gpu_usages'][epoch_number] = gpu_usages\n",
    "            metrics['vram_usages'][epoch_number] = vram_usages\n",
    "            metrics['disk_read_speeds'][epoch_number] = disk_read_speeds\n",
    "            metrics['disk_write_speeds'][epoch_number] = disk_write_speeds\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot CPU Usage\n",
    "plt.subplot(3, 2, 1)\n",
    "for epoch in selected_epochs:\n",
    "    plt.plot(metrics['steps'], metrics['cpu_usages'][epoch], label=f'Epoch {epoch}', marker='o')\n",
    "plt.title('CPU Usage vs Step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('CPU Usage (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot RAM Usage\n",
    "plt.subplot(3, 2, 2)\n",
    "for epoch in selected_epochs:\n",
    "    plt.plot(metrics['steps'], metrics['ram_usages'][epoch], label=f'Epoch {epoch}', marker='o')\n",
    "plt.title('RAM Usage vs Step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('RAM Usage (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot GPU Usage\n",
    "plt.subplot(3, 2, 3)\n",
    "for epoch in selected_epochs:\n",
    "    plt.plot(metrics['steps'], metrics['gpu_usages'][epoch], label=f'Epoch {epoch}', marker='o')\n",
    "plt.title('GPU Usage vs Step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('GPU Usage (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot VRAM Usage\n",
    "plt.subplot(3, 2, 4)\n",
    "for epoch in selected_epochs:\n",
    "    plt.plot(metrics['steps'], metrics['vram_usages'][epoch], label=f'Epoch {epoch}', marker='o')\n",
    "plt.title('VRAM Usage vs Step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('VRAM Usage (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot Disk Read Speed\n",
    "plt.subplot(3, 2, 5)\n",
    "for epoch in selected_epochs:\n",
    "    plt.plot(metrics['steps'], metrics['disk_read_speeds'][epoch], label=f'Epoch {epoch}', marker='o')\n",
    "plt.title('Disk Read Speed vs Step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Read Speed (MB/s)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot Disk Write Speed\n",
    "plt.subplot(3, 2, 6)\n",
    "for epoch in selected_epochs:\n",
    "    plt.plot(metrics['steps'], metrics['disk_write_speeds'][epoch], label=f'Epoch {epoch}', marker='o')\n",
    "plt.title('Disk Write Speed vs Step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Write Speed (MB/s)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Returns for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you've already imported required libraries and set up your data as before\n",
    "\n",
    "# Read and extract returns for each epoch\n",
    "epoch_returns = {}\n",
    "\n",
    "# Loop through each log file and extract returns along with the epoch\n",
    "for log_file in log_files:\n",
    "    epoch_number = int(log_file.split('_')[-1].split('.')[0])\n",
    "    \n",
    "    with open(os.path.join(log_dir, log_file), 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        returns = np.array([step['returns'] for step in data['steps']])\n",
    "        # Reshape returns if necessary\n",
    "        returns = returns.flatten()\n",
    "\n",
    "        # print(np.mean(returns))\n",
    "        \n",
    "        # Store returns for the current epoch\n",
    "        epoch_returns[epoch_number] = returns\n",
    "\n",
    "# Plot returns vs steps for each epoch in separate graphs\n",
    "for epoch_number, returns in epoch_returns.items():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    steps = np.arange(len(returns))  # Create an array for step numbers\n",
    "    plt.plot(steps, returns, marker='o', label=f'Epoch {epoch_number}')\n",
    "    \n",
    "    plt.title(f'Returns vs Steps for Epoch {epoch_number}')\n",
    "    plt.xlabel('Step Number')\n",
    "    plt.ylabel('Returns')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show each plot\n",
    "    plt.show()\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Mean Return\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df['Epoch'], df['Mean Return'], marker='o', color='blue', label='Mean Return')\n",
    "plt.title('Mean Return vs Epoch Number')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Mean Return')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot Median Return\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df['Epoch'], df['Median Return'], marker='o', color='orange', label='Median Return')\n",
    "plt.title('Median Return vs Epoch Number')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Median Return')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abr_netllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
